{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Our First Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Bu bölümde kendi sınıflandırıcımızı yazacağız ve sınıflandırıcı, k-Nearest Neighbors'ın hurda bir versiyonu olack. Bu, en basit sınıflandırıcılardan biridir. Bölüm 4'te, bir veri setini içe aktardık ve onu train/test'e ayırdık. Bir sınıflandırıcıyı eğitmek için train kullandık ve ne kadar doğru olduğunu görmek için test ettik.\n",
    "\n",
    "Önceden sınıflandırıcıyı bu iki satırı kullanarak bir kitaplıktan içe aktarıyorduk.\n",
    "\n",
    "```py\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "my_classifier = KNeighborsClassifier()\n",
    "```\n",
    "\n",
    "Şimdi onları yorumlayıp kendi sınıflandırıcımızı yazacağız. Pipeline'nın  geri kalanı tamamen aynı kalacak. İris datası için bu sınıflandırıcın doğruluk oranı %90'nın üzerindeydi. Bu oranı yakalayabileceğimiz, kendi sınıflandırıcımızı yazmayı amaçlıyoruz.\n",
    "\n",
    "Yapmamız gereken ilk şey pipeline'ı düzeltmek..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement a class\n",
    "\n",
    "Sınıflandırıcımız için ScrappyKNN adında bir sınıf uygulayacağız. Sınıfımız **fit** ve **predict** davranşlarına sahip olacak.\n",
    "fit metodumuz, training setimizin features ve label'larını girdi olarak alacak. **predict** yöntemimiz ise girdi olarak test verilerimizin özelliklerini alır ve çıktı olarak, *label* döndürür. Şimdi rastgele bir sınıflandırıcı yazacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class ScrappyKNN():\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for row in X_test:\n",
    "            label = random.choice(self.y_train)\n",
    "            predictions.append(label)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .5)\n",
    "\n",
    "my_classifier = ScrappyKNN()\n",
    "my_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = my_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "İris veri setinde üç farklı çiçek türü olduğunu hatırlayın, bu nedenle doğruluk yaklaşık% 33 olmalıdır. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38666666666666666"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to k-NN\n",
    "\n",
    "Ekranda gördüğümüz noktaların, fit metoduyla ezberlediğimiz eğitim verileri olduğunu hayal edin.\n",
    "\n",
    "<img src = 'https://raw.githubusercontent.com/birdalugureren/Machine-Learning-Recipes/master/img/knn1.png?token=AGJJGUDR5SV7U5OJKMB7HM276I5KS'>\n",
    "\n",
    "Şimdi, gri olarak belirtilen bu test noktası için bir tahmin yapmamızın istendiğini hayal edin. Bunu nasıl yapabiliriz?\n",
    "\n",
    "k-NN (En yakın komşu), tam olarak göründüğü gibi çalışır yani test noktasına en yakın eğitim noktasını bulacağız sonra test noktasının aynı etikete sahip olduğunu tahmin edeceğiz. Bu örnekte *yeşil*.\n",
    "\n",
    "Bu örnekte ise nokta, en yakın yeşil noktaya ve en yakın kırmızı noktaya eşit uzaklıkta. Bir yol, beraberliği rastgele bozabilmemiz. Başka bir yol ise (k burada devreye girer) tahminimizi yaparken dikkate aldığımız komşuların sayısıdır.\n",
    "k=3 olsaydı, en yakın üçüne bakardık. Bu durumda, bunlardan ikisi yeşil ve biri kırmızıdır.\n",
    "\n",
    "<img src = 'https://raw.githubusercontent.com/birdalugureren/Machine-Learning-Recipes/master/img/knn3.png?token=AGJJGUGZP57IPHELRCESAGS76I5OA'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure distance\n",
    "\n",
    "En yakın komşuyu bulmak için iki nokta arasındaki düz çizgi mesafesini ölçeceğiz, tıpkı bir cetvelle yaptığınız gibi.\n",
    "Bunun için **Öklid Mesafesi** denen bir formül var ve işte formül şöyle görünüyor.\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/birdalugureren/Machine-Learning-Recipes/master/img/oclid.png?token=AGJJGUDJNWLVG7J43N76FUC76I5P6'>\n",
    "\n",
    "İki nokta arasındaki mesafeyi ölçer. Hesapladığımız mesafe hipotenüsün uzunluğudur.\n",
    "\n",
    "Şu anda iki boyutlu uzayda mesafeyi hesaplıyoruz çünkü veri setimizde sadece iki özelliğimiz var. Peki ya üç özelliğimiz veya üç boyutumuz olsaydı? O zaman bir küpün içinde olurduk. Uzaydaki mesafenin bir cetvelle nasıl ölçüleceğini hala görselleştirebiliriz. Peki ya iriste yaptığımız gibi dört özelliğimiz veya dört boyutumuz olsaydı? Şimdi bir hypercube'teyiz.\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/birdalugureren/Machine-Learning-Recipes/master/img/hypercube.png?token=AGJJGUDNIYRZJALJN7VCW3K76I5RG'>\n",
    "\n",
    "İyi haber, Öklid Mesafesinin boyutların sayısına bakılmaksızın aynı şekilde çalışmasıdır. Daha fazla özellikle, denkleme daha fazla terim ekleyebiliriz.\n",
    "\n",
    "\\begin{equation*}\n",
    "d(a,b) = \\sqrt{(x_{2}-x_{1})^2 + (y_{2}-y_{1})^2 + ... +(n_{2}-n_{1})^2}\n",
    "\\end{equation*}\n",
    "\n",
    "Şimdi Öklid mesafesini kodlayalım. **scipy** adlı bir kitaplık kullanacağız. Burada, a ve b sayısal özelliklerin listesidir. a, eğitim verilerimizden bir nokta ve b, test verilerimizden bir nokta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def euc(a,b):\n",
    "    \"\"\"\n",
    "    Returns the distance between them.\"\"\"\n",
    "    return distance.euclidean(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement nearest neighbor algorithm\n",
    "\n",
    "Şimdi bir sınıflandırıcı için algoritmaya bir göz atalım. Tüm eğitim noktalarına olan mesafeyi hesaplayacağız. Sonra test noktasının en yakın olanla aynı etikete sahip olduğunu tahmin edeceğiz. Yaptığımız rastgele tahmini sileceğiz ve onu test noktasına en yakın eğitim noktasını bulan bir yöntemle değiştireceğiz. Bu eğitim için k=1 sabit tutacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScrappyKNN():\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for row in X_test:\n",
    "            label = self.closest(row)\n",
    "            predictions.append(label)\n",
    "        return predictions\n",
    "    \n",
    "    def closest(self, row):\n",
    "        best_dist = euc(row, self.X_train[0])\n",
    "        best_index = 0\n",
    "        for i in range(1, len(self.X_train)):\n",
    "            dist = euc(row, self.X_train[i])\n",
    "            if dist < best_dist:\n",
    "                best_dist = dist\n",
    "                best_index = i\n",
    "        return self.y_train[best_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classifier = ScrappyKNN()\n",
    "my_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = my_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
